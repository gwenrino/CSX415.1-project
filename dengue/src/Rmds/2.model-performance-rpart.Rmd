---
title: "Tree Model Performance"
author: "Gwen Rino"
date: "4/20/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, warning=FALSE, message=FALSE}
library(tidyverse)
library(caret)
```

## Model description  

This decision tree model uses all the variables except `week_start_date`, which is the unique identifier. It includes the engineered feature `year.season`. I ran the model with missing values imputed two ways, first by median values and second by k nearest neighbor values. I used the `caret` package to cross validate these models using the bootstrapping method.

```{r}

source("~./src/LoadData/Load.R") # HELP
source("~./src/Munge/Munge.r") # HELP
source("~./src/Models/2.Tree.R") # HELP

# With knn imputation
tree_2 <- train(total_cases ~ . -week_start_date,
                data = dengue.knn,
                method = "rpart")

# With median value imputation
tree_3 <- train(total_cases ~ . -week_start_date,
                data = dengue.med,
                method = "rpart")
```

## Model evaluation

Both the cross validations returned best models with the tuning parameter cp = 0.016. However, in both these cases the MAE was a bit greater than 20 -- better than the Naive and Linear models, but not by much. There was little difference between the MAEs of the rpart models with different imputation methods, which makes sense because a tree model shouldn't be very sensitive to this kind of preprocessing.

Most of the nodes in the visualized decision trees concern elements of time rather than weather. Again, it is clear that time is critical to understanding this data set. I need to learn about time series!

```{r}
print(tree_2) 
print(tree_3)
```

